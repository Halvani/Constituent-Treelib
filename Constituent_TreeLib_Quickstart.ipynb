{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nltk\n",
    "from nltk import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle GPU issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you have weak GPU (e.g., 2gb), it is highly recomended to use the CPU in order to prevent an out-of-memory exception caused by torch, which is used within benepar. For this, we just need to override the \"cuda.is_available\" function. However, if you have a more powerful GPU, just leave the following lines commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch \n",
    "# torch.cuda.is_available = lambda : False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constituent_treelib import ConstituentTree, BracketedTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the NLP pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To instantiate a ConstituentTree object, a spaCy-based NLP pipeline that incorporates the benepar component is required. Although you can set up this pipeline yourself, it is recommended (and more convenient) to let the library do it for you automatically via the create_pipeline() method. Given the desired language, this method creates the NLP pipeline and also downloads the corresponding spaCy and benepar models, if requested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = ConstituentTree.Language.English\n",
    "spacy_model_size = ConstituentTree.SpacyModelSize.Medium\n",
    "\n",
    "nlp = ConstituentTree.create_pipeline(language, spacy_model_size, download_models = True)\n",
    "# nlp = ConstituentTree.create_pipeline(language, spacy_model_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "'Stanley Getz was an American jazz saxophonist.',\n",
    "# 'It looks like the input tree may contain children with the same name. ',\n",
    "# 'The bridge was unfinished when it collapsed.'\n",
    "# 'The 2022 season is underway and there are a limited number of Single Game Tickets on sale now!'\n",
    "# 'And with no Wild Card possibilities for either team, the game is essentially a winner-take-all endeavor.'\n",
    "# 'You must construct additional pylons!',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [\n",
    "# 'In einer Gaspipeline in Litauen hat es eine Explosion gegeben.',\n",
    "# 'Für Fragen zu Freiwilligendiensten, nutzen sie bitte unser Forum!',\n",
    "# 'Der Künstler verlegt seit 30 Jahren Stolpersteine, die er zur Erinnerung an die Opfer des Nationalsozialismus Häusern platziert.'\n",
    "# 'Damit erlangen schützenswürdige Kundendaten in den Geschäfts- und Serviceprozessen der Wertschöpfungskette im Bereich Automotive eine immer größere Bedeutung.',\n",
    "# 'Die USA haben mit ihrem Investitionsprogramm für Klimaschutz reichlich Unmut der EU auf sich gezogen.',\n",
    "# 'Die methodische Grundlage der Autorenerkennung bildet die Fehler- und Stilanalyse.',\n",
    "# 'Ebenso empfehlenswert ist das Lesen einer Tageszeitung des Landes.', \n",
    "# 'Wie viel wird pro Jahr ungefähr weltweit benötigt?'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [    \n",
    "# 'Nous irons plus tard au théâtre.',\n",
    "# 'Pablo Ruiz Picasso était un peintre, dessinateur, sculpteur et graphiste espagnol.', \n",
    "# 'Découvrez une belle sélection d’évènements pour fêter la nouvelle année en partenariat avec Party.',\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swedish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [\n",
    "# 'Vilken vacker skog!',\n",
    "# 'Det var mycket åska och blixtar i går!',\n",
    "# 'För den närmaste veckan finns ingen uppenbar risk för fjärrtransport.'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [\n",
    "# 'W dodatku szczerze wierzy, że w tej wojnie stawką jest istnienie Rosji.',\n",
    "# 'Poproszę pięć kilo ziemniaków.',\n",
    "# 'Przepraszam, ale nie rozumiem.',\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [\n",
    "# 'A pizza tényleg kiváló volt!',\n",
    "# 'Vannak kisebb és kiszámíthatatlan kivételek a szabály alól.',\n",
    "# 'Ezt azért tesszük, hogy javítsuk és finanszírozzuk szolgáltatásainkat.' \n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chinese "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [\n",
    "# '你好吗？',\n",
    "# '很高兴见到你。',\n",
    "# '不好意思， 我没听懂。',\n",
    "# '请再说一遍。',    \n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Korean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [\n",
    "# '말을 냇가에 끌고 갈 수는 있어도 억지로 물을 먹일 수는 없다'\n",
    "# '반갑습니다', \n",
    "# '잘 지내세요?',\n",
    "# '그 집은 한국에서 지어졌어요'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate a ConstituentTree object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... from a raw sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tree = ConstituentTree(sentences[0], nlp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... from a bracketed tree string (wrapped as a BracketedTree object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bracketed_tree_string = '(S (NP (PRP You)) (VP (MD must) (VP (VB construct) (NP (JJ additional) (NNS pylons)))) (. !))'\n",
    "bracketed_tree = BracketedTree(bracketed_tree_string)\n",
    "\n",
    "tree_from_bracketed = ConstituentTree(bracketed_tree, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... from an nltk.Tree object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_tree_obj = Tree('S', [Tree('NP', [Tree('PRP', ['It'])]), Tree('VP', [Tree('VBZ', ['looks']), Tree('SBAR', [Tree('IN', ['like']), Tree('S', [Tree('NP', [Tree('DT', ['the']), Tree('NN', ['input']), Tree('NN', ['tree'])]), Tree('VP', [Tree('MD', ['may']), Tree('VP', [Tree('VB', ['contain']), Tree('NP', [Tree('NP', [Tree('NNS', ['children'])]), Tree('PP', [Tree('IN', ['with']), Tree('NP', [Tree('DT', ['the']), Tree('JJ', ['same']), Tree('NN', ['name'])])])])])])])])]), Tree('.', ['.'])])\n",
    "\n",
    "tree_from_nltk = ConstituentTree(nltk_tree_obj, nlp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Instantiate a compact ConstituentTree (without postag nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree_compact = ConstituentTree(sentences[0], nlp, remove_postag_nodes=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_compact.export_tree('compact.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree representations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  SVG representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretty-print bracketed tree string representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tree) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ASCII art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_tree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LATEX code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_tree.pformat_latex_qtree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constituent Treelib relies on the following two open-source tools to export the constructed constituent tree into various file formats:\n",
    "\n",
    "1.) To export the constituent tree into a PDF, the command line tool *wkhtmltopdf* is required: \n",
    "https://wkhtmltopdf.org/downloads.html\n",
    "Once downloaded and installed, the path to the wkhtmltopdf binary must be passed to the export function. However, in case of a Windows OS, an attempt is made to locate the path of the wkhtmltopdf binary by looking up the default installation directory (\"Program Files/wkhtmltopdf\"). \n",
    "\n",
    "2.) To export the constituent tree into the file formats JPG, PNG, GIF, BMP, EPS, PSD, TIFF and YAML, the software suite *ImageMagick* is required: https://imagemagick.org/script/download.php. \n",
    "\n",
    "#### Supported file formats are: [.pdf, .svg, .ps, .png, .jpg, .gif, .bmp, .psd, .eps, .tiff, .txt, .tex, .json, .yaml]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_tree(destination_filepath='my_tree.svg', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only phrasal categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.extract_all_phrasal_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All phrases (including nested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    all_phrases = tree.extract_all_phrases(avoid_nested_phrases=False, min_words_in_phrases=1)\n",
    "    for phrasal_category, phrases in all_phrases.items():\n",
    "        print(phrasal_category, phrases)\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All phrases (without nested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    all_phrases = tree.extract_all_phrases(avoid_nested_phrases=True, min_words_in_phrases=1)\n",
    "    for phrasal_category, phrases in all_phrases.items():\n",
    "        print(phrasal_category, phrases)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only noun phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = tree.extract_all_phrases(avoid_nested_phrases=True)\n",
    "noun_phrases = phrases['NP']\n",
    "\n",
    "print(noun_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract text units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only text tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.extract_leaves_from_tree(tree.nltk_tree, content_type=tree.NodeContent.Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.extract_leaves_from_tree(tree.nltk_tree, content_type=tree.NodeContent.Pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combination of both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.extract_leaves_from_tree(tree.nltk_tree, content_type=tree.NodeContent.Combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
